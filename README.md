# Aura ğŸ”
AI-Powered Surveillance System for Real-Time Behavioral Anomaly Detection

## ğŸŒŸ Overview
**Aura** is an end-to-end video intelligence system that detects behavioral anomalies (Loitering, Running, Abandoned Object) from CCTV footage in real time. Built for the Honeywell Hackathon, Aura combines YOLOv8 detection, multi-object tracking, rule-based anomaly logic, and a clean Streamlit dashboard with alert logs, screenshots, and one-click PDF reporting. Experimental modules include Autoencoders (unsupervised anomaly detection) and GAN-based rare-event synthesis.

**Demo Video:** https://drive.google.com/file/d/1M-OuE4elwFSp2ZLw8SMpe3dDoyYRFovW/view?usp=sharing  

## ğŸš€ Features
- **Real-Time Detection & Tracking**: YOLOv8 + persistent IDs across frames  
- **Anomalies Detected**:
  - **Loitering**: stationarity beyond time & radius thresholds
  - **Running**: sudden high displacement between frames
  - **Abandoned Object**: ownerâ€“object link broken for â‰¥ threshold
- **Interactive Dashboard (Streamlit)**: live overlays (green = normal, red = anomaly), timestamped alert panel, screenshots grid
- **PDF Reporting (ReportLab)**: one-click export with alerts + evidence
- **Advanced (Optional)**: Autoencoder (unsupervised) and GAN synthesis for rare scenarios

## ğŸ—ï¸ Tech Stack
| Component | Technology |
|---|---|
| Detection | Ultralytics YOLOv8 (nano by default) |
| CV / Utils | OpenCV, NumPy, Pillow |
| UI | Streamlit |
| Reporting | ReportLab (PDF) |
| Optional AI | Autoencoders (PyTorch), GANs (for rare event synthesis) |

## ğŸ“ System Architecture
![System Architecture](files/sysarch.png)

## âš™ï¸ Installation & Setup
1) Clone & env
```
git clone https://github.com/bhavika1304/Aura-Real-Time-AI-Anomaly-Detection-System.git
cd Aura-Real-Time-AI-Anomaly-Detection-System
python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate
```

2) Install deps
```
pip install -r requirements.txt
# or minimal set:
pip install streamlit ultralytics opencv-python reportlab pillow numpy
```

3) Run the dashboard
```
streamlit run dashboard.py
Open the local URL â†’ upload an .mp4/.avi â†’ Start Processing.
```

4) CLI prototype 
```
# Set VIDEO_PATH inside main.py, then:
python main.py
```

## ğŸ”§ Configuration (in code)

Resolution policy
```
TARGET_WIDTH = 800   # frames are resized to width 800 (keeps aspect)
```
Loitering
```
LOITER_TIME_THRESH = 5   # seconds
LOITER_DIST_THRESH = 20  # px radius at resized resolution
```
Running
```
RUNNING_SPEED_THRESH = 20  # px/frame instantaneous displacement
```
Abandonment
```
ABANDONMENT_TIME_THRESH = 5     # seconds
ABANDONMENT_DIST_THRESH = 100   # px from linked owner
```
Classes (COCO)
```
person (0), backpack (24), handbag (25), suitcase (26), briefcase (28)
```
Tips
â€¢ Thresholds are tuned for TARGET_WIDTH=800. If you change resolution, re-tune distances.
â€¢ If FPS is missing, default 30 FPS is assumed to convert seconds â†’ frames.

## ğŸ–¥ï¸ Dashboard

1. Video Upload: .mp4 / .avi
2. Live View: green boxes (normal), red boxes + label (anomaly)
3. Alerts Panel: timestamped anomalies (most recent first)
4. Screenshots Grid: 150Ã—150 crops captured at the alert moment
5. Generate Report: one-click PDF with summary + embedded screenshots

## ğŸ§  How It Works 
- Preprocess â†’ resize frames to width 800, read FPS (fallback 30)
- Detect â†’ YOLOv8 finds people & carry-on objects per frame
- Track â†’ stable IDs with position history across time
- Anomaly Engine:
  - Running â†’ large instantaneous displacement
  - Loitering â†’ positions within small radius for â‰¥ time window
  - Abandonment â†’ objectâ€“owner link broken (distance/time thresholds)
- UI â†’ draw overlays, log alerts, save cropped screenshots
- Report â†’ compile timestamped PDF with evidence

## ğŸ“‚ Folder Structure 
Aura-Real-Time-AI-Anomaly-Detection-System/
â”œâ”€ dashboard.py           # Streamlit UI (upload, live view, alerts, screenshots, PDF)
â”œâ”€ main.py                # CLI prototype for quick testing
â”œâ”€ assets/
â”‚  â”œâ”€ architecture.png    # optional: system diagram
â”‚  â””â”€ dashboard.png       # README screenshot
â”œâ”€ data/                  # optional: sample videos
â”œâ”€ requirements.txt
â””â”€ README.md

## ğŸ§ª Testing

- Functional: upload â†’ detect â†’ track â†’ flag anomalies â†’ verify alerts/screenshots
- Performance: YOLOv8n for CPU-friendly real time; YOLOv8s for higher accuracy (slower)
- Robustness: tune thresholds per camera/view; use Autoencoder for subtle anomalies
- Qualitative: validate on Avenue/UCSD style clips or your CCTV samples

## ğŸ“Š Results 

- Correctly flags Loitering, Running, Abandoned Object on sample surveillance clips
- Streamlit app provides live overlays, timestamped logs, evidence screenshots, PDF export
- Experimental:
  - Autoencoder improves coverage of subtle/unseen anomalies
  - GAN synthesis helps stress-test rare events
  - Full runs, clips, and logs: link your GitHub releases / demo folder

## âš ï¸ Challenges & ğŸ’¡ Learnings

- False positives from camera shake/occlusion â†’ mitigated with tracking + temporal checks
- Data scarcity for rare events â†’ augmented with GAN synthesis, tuned thresholds
- Real-time trade-offs on CPU â†’ use YOLOv8n and 800w resize; consider GPU/ONNX/TensorRT for scale
- UX matters â†’ alert logs + screenshots + PDF make the system practical beyond raw models

## ğŸ”­ Future Scope

- Multi-camera ingestion & centralized monitoring
- Edge deployment (ONNX/TensorRT)
- Spatio-temporal deep models (ConvLSTMs / ViT-based)
- Additional behaviors: restricted-area entry, tailgating, crowd panic
- Human-in-the-loop feedback to accept/reject alerts and auto-tune thresholds

## ğŸ‘©â€ğŸ’» Contributors
Bhavika Gandham (solo project for Honeywell Hackathon)
